== Proof of Concept

This directory contains the proof of concept that was built out prior to starting this
library. This code is *not* intended to live on, but instead is here to help inform
the work of building the library. As we build out the related pieces of the library
code should disapear from this part of the repository, until the poc/ directory
is completely gone.

== How to run

# Collect the raw data to work with
spark-submit --master yarn --deploy-mode client --jars /mnt/hdfs/wmf/refinery/current/artifacts/refinery-hive.jar data_prepare.py

# Train DBN for relevance estimates
spark-submit --master yarn --deploy-mode client --py-files /a/ebernhardson/feature_log/lib/python2.7/site-packages/clickmodels-1.0.2-py2.7.egg data_process_dbn.py
# Collect feature vectors for queries (can run in parallel with DBN)
spark-submit --master yarn --deploy-mode client --py-files /home/ebernhardson/kafka_python-1.3.4.dev-py2.7.egg data_process_features.py

# Copy es queries to somewhere that can send them into relforge
tar -cvf es_queries.tar -C /mnt/hdfs/user/ebernhardson/ltr/en.wikipedia_10S_150000Q es_queries
# run them, collect feature logs, ship them back here, copy to hdfs
zcat part-00*.gz | pv -l | parallel -j 32 curl -s http://localhost:9200/enwikibm25perfield_content/page/_search -d {} > /dev/null
...

# Parse logs
pyspark --master yarn parse_feature_logs.py

# Join the various bits of data into a final data frame
pyspark --master yarn merge_vector_data.py

# (TODO) Convert the vector data df to appropriate formats for ranklib, xgboost, lightgbm

